Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 1 (use --cores to define parallelism)
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	1	all
	1	find_bams
	2

[Thu Mar 31 14:40:26 2022]
Job 1: Searching for bams to archive...

Terminating processes on user request, this might take some time.
[Thu Mar 31 14:43:02 2022]
Error in rule find_bams:
    jobid: 1
    output: bamLocations.txt
    shell:
        
		touch bamLocations.txt
        find /scratch/general/lustre/u0854535/temp -name "*bam" > bamsFound.txt
		while IFS= read -r line
		do
			dir=$(dirname $line)
			echo $dir >> bamLocations.txt
		done
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)

Removing output files of failed job find_bams since they might be corrupted:
bamLocations.txt
Complete log: /uufs/chpc.utah.edu/common/home/u0854535/backup/readFile/.snakemake/log/2022-03-31T144026.282079.snakemake.log
